{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple First Pass Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# special matplotlib argument for improved plots\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a first pass naive prediction function, we will use a linear regression to model the relationship between a set of independent variables $X$ (which includes temperature, preciptation, previous price of wheat, and price of corn) and a dependent variable (our predicted price) $Y$.  This method assumes the relationship between each predictor $X$ is linearly related our price $Y$. We do not believe this is true, however, it is a starting point for exploring other models.  \n",
    "\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X $$\n",
    "\n",
    "This is the simplest form of linear regression (one variable), we'll call this the simple model. \n",
    "\n",
    "* $\\beta_0$ is the intercept of the linear model\n",
    "\n",
    "* Multiple linear regression where we would input all four factors together will be in the form\n",
    "    * $X_1$, $X_2$, $X_3$, $\\ldots$\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p  $$\n",
    "\n",
    "We can then estimate $\\beta_0$ by using the least squares approximation method  by minimizing the difference between the following: \n",
    "\n",
    "$$ S = \\sum_{i=1}^N r_i = \\sum_{i=1}^N (y_i - (\\beta_0 + \\beta_1 x_i))^2 $$\n",
    "\n",
    "where $N$ is the number of observations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
